{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyPythonNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV0Py9LJsar8",
        "colab_type": "code",
        "outputId": "b8c4d850-b5c4-482f-a2c4-eaffa013d7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# pwd is /content\n",
        "cd /content/drive/My Drive/deep-learning-v2-pytorch/convolutional-neural-networks/cifar-cnn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/deep-learning-v2-pytorch/convolutional-neural-networks/cifar-cnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWuh8XwBdsU",
        "colab_type": "code",
        "outputId": "599e50be-e217-4569-a489-760d1b384ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA-YGrIatXbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d5addee-0e7a-4006-a470-76dae96a02f5"
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 50\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "ntransform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.CIFAR10('data', train=True,\n",
        "                              download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10('data', train=False,\n",
        "                             download=True, transform=ntransform)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)\n",
        "\n",
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pROEvVkjtolB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c94df7f3-8d12-4a8b-f485-5236b28ceca4"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.Conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
        "        self.Conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
        "        self.Conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.Conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        \n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x =  self.bn1( F.relu( self.Conv1(x) ) )\n",
        "        x =  self.pool( self.bn2( F.relu( self.Conv2(x) ) ) ) \n",
        "        x =  F.dropout( self.pool(self.bn3( F.relu( self.Conv3(x) ) )), p = 0.2)\n",
        "        x =  F.dropout( self.pool( self.bn4( F.relu( self.Conv4(x) ) )) , p =0.2 )\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.dropout( F.relu(self.fc1(x)), p = 0.3)\n",
        "        x = F.dropout( F.relu(self.fc2(x)), p = 0.3)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (Conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (Conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (Conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (Conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZhBtYbvunDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "795b2b9f-558d-4f91-cece-80ebeea1b72b"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.3)\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 100 # you may increase this number to train a final model\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "train_lossA, valid_lossA = [], []\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    valid_loss = valid_loss/len(valid_loader)\n",
        "    train_lossA.append(train_loss)\n",
        "    valid_lossA.append(valid_loss)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.562138 \tValidation Loss: 1.271077\n",
            "Validation loss decreased (inf --> 1.271077).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 1.149354 \tValidation Loss: 1.065375\n",
            "Validation loss decreased (1.271077 --> 1.065375).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.981315 \tValidation Loss: 0.942954\n",
            "Validation loss decreased (1.065375 --> 0.942954).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.882145 \tValidation Loss: 0.911989\n",
            "Validation loss decreased (0.942954 --> 0.911989).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.815528 \tValidation Loss: 0.824106\n",
            "Validation loss decreased (0.911989 --> 0.824106).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.758329 \tValidation Loss: 0.795524\n",
            "Validation loss decreased (0.824106 --> 0.795524).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.716618 \tValidation Loss: 0.753402\n",
            "Validation loss decreased (0.795524 --> 0.753402).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.678221 \tValidation Loss: 0.739285\n",
            "Validation loss decreased (0.753402 --> 0.739285).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.651499 \tValidation Loss: 0.707216\n",
            "Validation loss decreased (0.739285 --> 0.707216).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.619236 \tValidation Loss: 0.686868\n",
            "Validation loss decreased (0.707216 --> 0.686868).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.591514 \tValidation Loss: 0.703954\n",
            "Epoch: 12 \tTraining Loss: 0.569635 \tValidation Loss: 0.664410\n",
            "Validation loss decreased (0.686868 --> 0.664410).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.550578 \tValidation Loss: 0.673358\n",
            "Epoch: 14 \tTraining Loss: 0.526098 \tValidation Loss: 0.657825\n",
            "Validation loss decreased (0.664410 --> 0.657825).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 0.514373 \tValidation Loss: 0.630710\n",
            "Validation loss decreased (0.657825 --> 0.630710).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.495486 \tValidation Loss: 0.630172\n",
            "Validation loss decreased (0.630710 --> 0.630172).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.479219 \tValidation Loss: 0.617512\n",
            "Validation loss decreased (0.630172 --> 0.617512).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.461867 \tValidation Loss: 0.637182\n",
            "Epoch: 19 \tTraining Loss: 0.445533 \tValidation Loss: 0.611533\n",
            "Validation loss decreased (0.617512 --> 0.611533).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 0.430748 \tValidation Loss: 0.627213\n",
            "Epoch: 21 \tTraining Loss: 0.420020 \tValidation Loss: 0.619088\n",
            "Epoch: 22 \tTraining Loss: 0.405863 \tValidation Loss: 0.602257\n",
            "Validation loss decreased (0.611533 --> 0.602257).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 0.394366 \tValidation Loss: 0.618101\n",
            "Epoch: 24 \tTraining Loss: 0.382199 \tValidation Loss: 0.604816\n",
            "Epoch: 25 \tTraining Loss: 0.374362 \tValidation Loss: 0.607634\n",
            "Epoch: 26 \tTraining Loss: 0.363774 \tValidation Loss: 0.604026\n",
            "Epoch: 27 \tTraining Loss: 0.350255 \tValidation Loss: 0.616436\n",
            "Epoch: 28 \tTraining Loss: 0.339693 \tValidation Loss: 0.608747\n",
            "Epoch: 29 \tTraining Loss: 0.332863 \tValidation Loss: 0.617369\n",
            "Epoch: 30 \tTraining Loss: 0.315760 \tValidation Loss: 0.606302\n",
            "Epoch: 31 \tTraining Loss: 0.314139 \tValidation Loss: 0.612937\n",
            "Epoch: 32 \tTraining Loss: 0.309498 \tValidation Loss: 0.601819\n",
            "Validation loss decreased (0.602257 --> 0.601819).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 0.300386 \tValidation Loss: 0.622029\n",
            "Epoch: 34 \tTraining Loss: 0.291823 \tValidation Loss: 0.615989\n",
            "Epoch: 35 \tTraining Loss: 0.284872 \tValidation Loss: 0.620972\n",
            "Epoch: 36 \tTraining Loss: 0.275535 \tValidation Loss: 0.615503\n",
            "Epoch: 37 \tTraining Loss: 0.270643 \tValidation Loss: 0.614772\n",
            "Epoch: 38 \tTraining Loss: 0.265767 \tValidation Loss: 0.607760\n",
            "Epoch: 39 \tTraining Loss: 0.263916 \tValidation Loss: 0.605694\n",
            "Epoch: 40 \tTraining Loss: 0.252904 \tValidation Loss: 0.609019\n",
            "Epoch: 41 \tTraining Loss: 0.254865 \tValidation Loss: 0.615454\n",
            "Epoch: 42 \tTraining Loss: 0.245092 \tValidation Loss: 0.620554\n",
            "Epoch: 43 \tTraining Loss: 0.236959 \tValidation Loss: 0.617965\n",
            "Epoch: 44 \tTraining Loss: 0.231020 \tValidation Loss: 0.637544\n",
            "Epoch: 45 \tTraining Loss: 0.228314 \tValidation Loss: 0.631872\n",
            "Epoch: 46 \tTraining Loss: 0.219612 \tValidation Loss: 0.644115\n",
            "Epoch: 47 \tTraining Loss: 0.216559 \tValidation Loss: 0.653901\n",
            "Epoch: 48 \tTraining Loss: 0.216682 \tValidation Loss: 0.647853\n",
            "Epoch: 49 \tTraining Loss: 0.209864 \tValidation Loss: 0.631190\n",
            "Epoch: 50 \tTraining Loss: 0.204318 \tValidation Loss: 0.654198\n",
            "Epoch: 51 \tTraining Loss: 0.203321 \tValidation Loss: 0.628424\n",
            "Epoch: 52 \tTraining Loss: 0.196626 \tValidation Loss: 0.656994\n",
            "Epoch: 53 \tTraining Loss: 0.189726 \tValidation Loss: 0.647209\n",
            "Epoch: 54 \tTraining Loss: 0.191139 \tValidation Loss: 0.632266\n",
            "Epoch: 55 \tTraining Loss: 0.184131 \tValidation Loss: 0.640940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-127e4b2aef0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6abaef5b6a0c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# add sequence of convolutional and max pooling layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La8QcCzc1U-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e38b6a11-894f-48b3-ede0-d87e879066d3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_lossA)\n",
        "plt.plot(valid_lossA)\n",
        "plt.show()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXzU1b3/8ddnJvu+J5CFJBAIyE5YrKKIG26g12qL1m5a2vurvb3dl3t7a+1te1u72da2okVba1Frq8WtSl1xQQirQNghkJCQnezLzJzfH2eAACEJZJLJTD7PxyOPycx8M9/PV4f3nDnfc75HjDEopZQKfA5/F6CUUso3NNCVUipIaKArpVSQ0EBXSqkgoYGulFJBIsRfO05JSTG5ubn+2r1SSgWkDRs21BhjUnt6zm+BnpubS3Fxsb92r5RSAUlESs/2XJ9dLiKyQkSqRGRbL9ssEJHNIrJdRN4830KVUkqdv/70oT8KLDrbkyKSAPwWWGyMuQC4xTelKaWUOhd9Brox5i2grpdNbgP+bow55N2+yke1KaWUOge+GOUyHkgUkTdEZIOIfPxsG4rIMhEpFpHi6upqH+xaKaXUcb4I9BBgFnAdcDXwHREZ39OGxpjlxpgiY0xRamqPJ2mVUkqdJ1+McikDao0xLUCLiLwFTAN2++C1lVJK9ZMvWuj/AC4WkRARiQLmAiU+eF2llFLnoM8WuoisBBYAKSJSBnwXCAUwxvzeGFMiIv8EtgIe4GFjzFmHOA7UzspGnttyhM/MzychKmywdqOUUgGnz0A3xiztxzb3Aff5pKI+lNa28sDr+7hm8igNdKWU6ibgruWSGhsOQHVTh58rUUqp4SXgAj3NG+hVTe1+rkQppYaXgAv0lBhtoSulVE8CLtAjQp3ER4ZqoCul1GkCLtDB9qNXaaArpdQpAjPQY8K1ha6UUqcJyEBPiwunulkDXSmlugvIQE+NCaeqsQNjjL9LUUqpYSMwAz02nLYuNy2dbn+XopRSw0ZABnpanHcseqOORVdKqeMCMtBTYyIAHYuulFLdBWagH5/+rydGlVLqhIAM9BPT/xs10JVS6riADPSEqFBCnaItdKWU6iYgA11EdHKRUkqdJiADHXT6v1JKnS6gA11b6EopdVIAB3oE1XpNdKWUOiGAAz2c2pZOXG6Pv0tRSqlhoc9AF5EVIlIlIr0u/Cwis0XEJSIf9l15Z5caG44xUNfSORS7U0qpYa8/LfRHgUW9bSAiTuDHwCs+qKlfTi5Fp/3oSikF/Qh0Y8xbQF0fm30B+BtQ5Yui+kMXi1ZKqVMNuA9dRDKBm4DfDbyc/kvVtUWVUuoUvjgp+kvgG8aYPs9OisgyESkWkeLq6uoB7TT1RJeLjnRRSimAEB+8RhHwhIgApADXiojLGPPs6RsaY5YDywGKiooGtDpFRKiTuIgQbaErpZTXgAPdGJN3/HcReRR4vqcwHwxpcRF6PRellPLqM9BFZCWwAEgRkTLgu0AogDHm94NaXR+OL0WnlFKqH4FujFna3xczxnxyQNWco9TYcLaUNQzlLpVSatgK2JmiYMei62LRSillBXSg62LRSil1UsAHOuhYdKWUggAP9LRYu1h0VaOORVdKqYAOdF0sWimlTgroQE/TLhellDohoAM9PtIuFq1XXFRKqQAPdIdDSNHFopVSCgjwQAfvWHQNdKWUCvxA18WilVLK0kBXSqkgEQSBHkFtS4cuFq2UGvECL9D3vQ7LL4Nmu9qdLhatlFJW4AW6wwlHNkLFVuDkUnR6YlQpNdIFXqBnTLG3lTbQ0+J0cpFSSkEgBnpkIiTknAh0XSxaKaWswAt0gIypJ7tcdLFopZQCAjXQR02Dun3Q0aSLRSullFdgBvqJfvRtgHcsul5xUSk1wgVooE+1t8dPjMZG6GLRSqkRr89AF5EVIlIlItvO8vztIrJVRD4QkXdFZJrvyzxN3GiISj6lH11b6Eqpka4/LfRHgUW9PH8AuNQYMwX4PrDcB3X1TsS20iu3ADr9XymloB+Bbox5C6jr5fl3jTH13rtrgSwf1da7UVOhaie4OkmLDae1001zh2tIdq2UUsORr/vQ7wReOtuTIrJMRIpFpLi6unpge8qYCp4uqN6pi0UrpRQ+DHQRuQwb6N842zbGmOXGmCJjTFFqaurAdjjK21VfuVUDXSml8FGgi8hU4GFgiTGm1hev2aeksRAaDRVbSYuNAHRykVJqZBtwoItIDvB34A5jzO6Bl9RPDgdkTNYWulJKeYX0tYGIrAQWACkiUgZ8FwgFMMb8HvgfIBn4rYgAuIwxRYNV8CkypsKWlSREOHWxaKXUiNdnoBtjlvbx/F3AXT6r6FxkTIH1D+FoOKiLRSulRrzAnCl63CjvjNGKLToWXSk14gV2oKdNAkcIVH5ARlwEh+tb/V2RUkr5TWAHekg4pBZC5VamZSewv7qFel2KTik1QgV2oMOJa6MXjUkEYENpfR9/oJRSwSnwA33UVGipYlpCO6FOYX3pWa9SoJRSQS3wA917Kd2Imu1MyYyn+KC20JVSI1MQBPrxxS62MDs3ia1lDbR3uf1bk1JK+UHgB3pEHCTm2X703CS63IatZcf8XZVSSg25wA90sK30yq3M8p4YXX9Q+9GVUiNPcAT6qKlQf5AkZxvj0mJ0pItSakQKjkDPOH4p3W0UjUmk+GAdHo/xb01KKTXEgiPQR51cNLooN4nGdhd7qpr9W5NSSg2x4Aj02AyIToOKrczO1X50pdTIFByBDjB6OpStIycpitTYcIo10JVSI0zwBHrBVVC7F6nZzezcRNbrBCOl1AgTPIFeeL29LVlF0ZgkyhvaONLQ5t+alFJqCAVPoMeNgqw5UPIcs3OTACjW4YtKqREkeAIdYOINULGFiZH1RIU52aD96EqpESTIAt12u4Tsep4ZOQnaj66UGlGCK9CT8iF9CpQ8R9GYJHZWNtLY3uXvqpRSakj0GegiskJEqkRk21meFxH5lYjsFZGtIjLT92Weg4k3wOH3+VC6C4+BTYca/FqOUkoNlf600B8FFvXy/DVAgfdnGfC7gZc1AJMWA4ZpLe/gdIiOR1dKjRh9Brox5i2gt1RcAvzJWGuBBBEZ5asCz1lqISSPI2LPC0waFaczRpVSI4Yv+tAzgcPd7pd5HzuDiCwTkWIRKa6urvbBrnvcie12ObiGi7OcbD7cQKfLMzj7UkqpYWRIT4oaY5YbY4qMMUWpqamDt6OJN4DHxaLQTbR3edh+RBe8UEoFP18EejmQ3e1+lvcx/xk9E+KyKKx/A4C399T4tRyllBoKvgj0VcDHvaNd5gHHjDEVPnjd8+ftdgk/+AaXjInkqQ2H9froSqmg159hiyuB94AJIlImIneKyOdE5HPeTV4E9gN7gYeA/zdo1Z6LiTeAu4Mv5BzgcF0b7+6r9XdFSik1qEL62sAYs7SP5w3weZ9V5Cs58yAqhZkta0iIuo2V6w5xcUGKv6tSSqlBE1wzRbtzOKHwOpx7V3PLtFRe2VFJbXOHv6tSSqlBE7yBDjBxMXQ2c2fiZrrchr9tLPN3RUopNWiCO9DzLoGMKWS8/mX+N2U1T7x/CNtDpJRSwSe4Az0kDD71T5h0Ix9rfoSvNf6A9bsP+bsqpZQaFMEd6ADhMfDhFXRd/n2udG4g52/XQ/Vuf1ellFI+F/yBDiBC6Pz/4E/j7ie0owHz0GVQ8py/q1JKKZ8aGYHuNW/hjVzX8QOqI3LhqY9DzR5/l6SUUj4zogJ90ug40rPH8nnP1zGOUHjvAX+XpJRSPjOiAh1g6exs1teEUDP2RtiyElp0BqlSKjiMuEC/YdpoosOcPOK+DlztULzC3yUppZRPjLhAjw4PYfH0TFbsDqMj73JYtxy62v1dllJKDdiIC3SAz8zPw+0x/NFzHbRUwban/V2SUkoN2IgM9PzUGD59UR4/3JVOW2KhPTmqM0iVUgFuRAY6wBcuLyAtNoIHu66Bqh2w7zV/l6SUUgMyYgM9JjyEb11byAM1M2gLT4X3fuPvkpRSakBGbKAD3Dg9k2ljUvlD5xW2hX50h79LUkqp8zaiA11E+N6SC1jRvoAuCdeJRkqpgDaiAx3ggtHxXDv3Ap5wXYJn61PQdNTfJSml1HkZ8YEO8JUrJ/DXkBvA04V56z4d8aKUCkj9CnQRWSQiu0Rkr4h8s4fnc0TkdRHZJCJbReRa35c6eBKjw7j16gU86VqArH8IVi7VSwIopQJOn4EuIk7gAeAaYBKwVEQmnbbZfwNPGWNmAB8FfuvrQgfb0jk5PJ72Ze5zfBqz71X4/UVw4C1/l6WUUv3Wnxb6HGCvMWa/MaYTeAJYcto2Bojz/h4PHPFdiUPD6RDuu2U6yzuu5EeZv8GExcAfF8Or3wd3l7/LU0qpPvUn0DOBw93ul3kf6+4e4GMiUga8CHzBJ9UNsYmj4vjylRNYvjuGFy5cCTNuhzU/hUeuhaZKf5enlFK98tVJ0aXAo8aYLOBa4DEROeO1RWSZiBSLSHF1dbWPdu1byy7JZ9aYRL79/H4qFvwUbv4DHN0Oj90ErXX+Lk8ppc6qP4FeDmR3u5/lfay7O4GnAIwx7wERQMrpL2SMWW6MKTLGFKWmpp5fxYPM6RB+dss0utyGrz+9FTP5Zli6Emr3wuO3QEezv0tUSqke9SfQ1wMFIpInImHYk56rTtvmEHA5gIhMxAb68GyC90NuSjT/dd1E1uyp4c9rSyH/UvjwI3BkEzxxG7g6/F2iUkqdoc9AN8a4gLuBl4ES7GiW7SJyr4gs9m72FeAzIrIFWAl80pjAHsx9+9wcLhmfyg9f3MmBmhaYeD0seQAOvAlPfxrcLn+XqJRSpxB/5W5RUZEpLi72y777q/JYO1f/8i3Gpkbz1GcvJMTpgLW/h39+A6bfDot/Aw6dm6WUGjoissEYU9TTc5pGvciIj+DeJRew8VAD33tuB8YYmPc5WPAt2Pw4PP+f0Fjh7zKVUgqAEH8XMNwtmZ7JjopGHnxzP7ERIXx9USFc+g3oaLKX3N34J9vHPvUjMPEGCI/1d8lKqRFKW+j98M1Fhdw2N4ffvrGP376xF0Tg6h/A3Rvg0q9D/UF49t/hvgLbv35ks79LVkqNQNpC7wcR4ftLJtPS4eIn/9xFbHgId1yYCynj4LJv2y6YsvWw9UnY9jcoeR4W/wqmfdTfpSulRhBtofeT0yH89JZpXDExje/8YzvPbCo7+aQIZM+B635mW+3Zc+CZz8Ir/w0et/+KVkqNKBro5yDU6eA3t83kwvxkvvrXrby8vYfLAUQnwx3PwJxl8O6v7WSktvqhL1YpNeJooJ+jiFAnD32iiCmZ8dz9l42s3tHDghjOULj2PrjhfnvFxocuh+rdQ1+sUmpE0UA/DzHhIfzxU3OYNCqOf//zBl764CxDF2d9Ej7xHLQfg4cvh3d+BV1tvb+4qxN2vqjDIZVS50wD/TzFR4Xy2F1zmZoVz90rN/HclrNcMXjMhbDsDciaDau/A/dPh3UPnXn5gJYaeOs++OUUeGIprLgKGg4N9mEopYKIBvoAxEWE8qc75zIrJ5EvPrHp1BOl3SVkwx1/h0++CEn58OJX4ddFsPExqNgC//g8/HwSvPa/kD4Jrv8FtB2DR6+HhsM9v6ZSSp1Gp/77QGunizsfLWbtgVp+fPNUbi3KPvvGxsC+12x4H9loHwuJtEMc534O0grtY+Ub4E83QVQifPIFiM8a/ANRSg17vU3910D3kbZON8seK2bNnhq+eU0hy+bn43DI2f/AGNj9TzhWBpNvhqikM7cp2wCP3QhRyd5QP31dEaXUSKOBPkTau9x86cnNvLStkjl5SfzslmlkJ0UN7EXLiu3iGlHJ8KkX7W3FFji0Fg6/D4fXQUi4vVjYjI/Z7h2lVNDSQB9Cxhie3lDGvc/twG0M/33dJJbOyUakl9Z6Xw6vt6HuDIHOFnB32scT8yB7LrRU224cgIIrYeYnYPzVdvikUiqoaKD7QXlDG994eitv763hkvGp/OTmqWTER5z/Cx5eD+/8EpK8IZ49F2LSTj5fXwqbHoNNf4amCojJsJclmPlxO5NVqWDjcUP1LohMgNhR5/c+NwYqP4C0iX03gLra4d1fQWcz5M63/wYj4s6v9gHQQPcTj8fw+Pul/PDFnYQ6hV98ZDqXT0wf3J26XbB3tR3zfuhdGH+Nva5M9/BXKhC5XVC5FQ6+bX8OvQcdjfa5sBhIHgsp4yG5ADImw7grISTs7K93dAe89HU4uAYyptoFbEZN7Xnbqp32wntV28ERCp4uECeMng5jLoK8SyDv0t735yMa6H52sKaFu1duZPuRRr5+dSGfuzR/YF0w/eHxwPu/h3/dA+ExcP0vYdLiPv9MqWGltc4OHtj5gp11fTzAk8dB7sWQPQ+6WqBmz8mfY4cBAzHpUPRpO8EvNuPka7bVw+s/gvUP2xb2rE/Zb7ZtdXDxl+GSr9rzUmBb8Bv/CC99E8Ki4cbf2f2WrTv5wVJWbAM+KtleRnv67fYDpSeNFfZvE8bYD4PzoIE+DLR1uvna01t4fmsFS6aP5sc3TyUi1Dn4O67aaS8UVrEZpi2Fa34MEfHn91rN1fDu/bZ757Jv26+pSp0rjwdKVsHa39puk+Sxdn5G0lhIzoewWNj7Lxvih94F44HY0TD+KtvVkXvxqQF9us5WG7Trlttvq44QmLTEXl+pqgRevRfaG2zYX/ZfdoRZax28/G3YshJSJ9rWevJYeO6LsONZyF8ANz3Y8347W20rf/Pjdpa3pwtGTbeDFDKmQPlGG+Jlxd4PG2DOZ+Han5zXfz4N9GHCGMMDr+/lp6/sZmpWPMvvKBpYv3p/ubvgzZ/Amp9BaJTtcxSHfaM7nPY2Kd8u0DF+kX2+u+NBvv4P4Gq3/+C6WuGSr8HFXzr718yWWjjwBiTmQvrkk60eNTJ5PFDyD/terNphW9lxo6F2PzT2MCkvbRIUXgcTroXRM86vj7x2n33fbvozdByzj425yDZsMqacuf2e1TbEmyogKsW22hd+Bz70H/1bbrKlFj74K2z+s+2bPy4+284Wz5ptr8aaMeW8/z1ooA8zr2yv5EtPbiY6PIQH75jFjJzEodlx2QZ74tTdaVtGHhcYtw388o3QdMSGe96ltnsm50K7/fEgn3KrDfHIBHjpG7DtaRvUi38NmTPtPoyxrZUNj0LJcydH5DhC7dfQ0TPttmMusid4+8PVEbwfBg2HYd2D9r9b8jjbB5xSANGpJwOsvREaSu2lIOpLbYs1Kc9+CCfmQmikXw+B9mO2roZSaKq09UQk2PfJ8duy9fDGj6G6xB7jJV+Hyf9mGxRgr3FUf9AGcGutbYUnj/VdjR3NtqUdkWA/JHr7cGhvhH9919Z8/f2QNev89lmx1bbIR8+EuFHn9xo9GHCgi8gi4H7ACTxsjPm/Hra5FbgHMMAWY8xtvb3mSA50gJ2VjXzmT8VUHmvny1dOYNkl+Th7m4g02DweO3O1ZBXsWAX1B+zj4jgZ5CnjTv2bXS/B81+C5qPwoS/YFs2GR6Fun+3WmbbUTppqPGJfu3yjXc2ps8n+/bgr7FfPcVec2frpbIXtz8CGR+w/rOx5NgAmLen963Z/HCuzX+d3vWgvhjZq2smflPF2eKjbZcOnbL39qly23n4tz7vE1jvu8p7r6GqDmt1wrNy2Ks/2D7mpEtb83B6fMTbYXO0nn4+It90MTRW2e6A3cZl2CGt4jPdbV4gdseEIsf2+qYX2gzd90vl3t7k6oW4/VO+0I0uqd9r7DaX9vzx0ygS7wtcFN50McnXOBhToIuIEdgNXAmXAemCpMWZHt20KgKeAhcaYehFJM8ZU9fa6Iz3QARpaO/n2Mx/w4geVzM1L4ucfmU5mgp9bW2AD5uh2KH0Hxl5+ZpB319ZgLzq28U/2fvY8KPqUDd6eWo4eD9Tuta2l9X+A5krbdzpnGUy/DRrLofgR2PqEbfklF9ix9fvftCMMENu6n3wTZEyzYXLip87+TViMHdUTkwbRafbkmLvTBvjO5+HIJltLygQbcEe32S4kgJAI21KuO2BPtoE92ZU12267/w37AQaQPsUGuzPU9s1WldgPQuM5ebzHtym40g5za2+Ed34B6x62Nc34mP2wjMu03Q41u6FmL9TusSfQYjMgcQwk5NgTaQljbOuy/oCtsW6//ak/aI/B7bJ9uB6X/b294eSJRLBf/dMvsLfhsfZDICzW/h4aabdtqbYXi2upsb83ltt9eFzeFxFbT/I4W1tirq0rcYz9EHK12fdFe8PJ26gUmHCNBrkPDDTQLwTuMcZc7b3/LQBjzI+6bfMTYLcx5uH+FqWBbh2fiHTPqu04HMIPbprC4mmj/V3Wuav8wHarHL8WTX+4Ou03gvcftCeNQiJsK9UZBhMX2w+GMRed/HpctdO22rf/3QbfGcQGU2eL7UrqSWaR/co98QbbtQG2+6l2r/32ULEFanbZ7oys2ZBVZFu/x2swxn4A7FkNe1+Fw2vtY0n59iRx2kTbIo4bbYfV7X3V3npcNjgxNnin3Gpbq77sVuiJMTaQj+6wdR/dbn+aK+1C5ydC+jRhMRCdYoM4NsMeU2ohpHqHBYYNcAa0Om8DDfQPA4uMMXd5798BzDXG3N1tm2exrfiLsN0y9xhj/tnDay0DlgHk5OTMKi0tPb8jCkKltS186cnNbDzUwI3TR/O9JZOJjxxBMz3LN8Lmv9hLF0y/3YbJ2RhjW8PHyuwIhchE+xMRb1uAHrftHmmpgmbvj6cLxi60QetLnS22a6O3Pv72Rjvkbu9qG6Af+g9IneDbOs6HMfb8RGezbZl3ttr/htEp/u+XV2c1FIH+PNAF3ApkAW8BU4wxZ+380xb6mVxuDw+8vo9fvbaHuIgQ/vOK8dw2N4dQp17lWCll9Rbo/UmKcqD7FZ+yvI91VwasMsZ0GWMOYFvrBedT7EgW4nTwxSsKWHX3RUwcFcd3V23nql+8xcvbK/HXaCSlVODoT6CvBwpEJE9EwoCPAqtO2+ZZYAGAiKQA44H9PqxzRLlgdDyP3zWXFZ8swukQPvvYBj6yfC1bDvcx2kEpNaL1GejGGBdwN/AyUAI8ZYzZLiL3isjxueQvA7UisgN4HfiaMaZ2sIoeCUSEhYXp/POL8/nfGyezr6qZJQ+8w11/XM9mDXalVA90YlGAaGrvYsXbB3nk3QM0tHYxvyCFLywsYE5eDwtjKKWCls4UDSLNHS4eX1vKQ2v2U9PcyZy8JL585Xjm5Sf7uzSl1BDQQA9CbZ1unlh/iAff3E9lYzv/NiOT/7puIskxQTpFXikFDHyUixqGIsOcfOqiPN742gK+sHAcz209wsKfvcmT6w/h8eiIGKVGIg30ABcR6uQrV03gpS/OZ0J6LN/42wd8ZPl77D7a5O/SlFJDTLtcgojHYy8j8MOXSmhud7GwMI0rJqazoDCVtNghuEyvUmrQ9dblEjLUxajB43AIt87O5vKJafz6tb28vL2SV3bYC0lNy4rn8onpXHVBOoUZQ78OolJq8GkLPYgZYyipaOLVkqO8urOKLWUNGAPzC1L4/GXjmJuXNPhL4SmlfEpHuSgAqps6+NvGMh72DnksGpPI5y8bx4IJqRrsSgUIDXR1ivYuN0+uP8yDb+7jyLF2Lhgdx2cvHcuiCzIIC9Hz5EoNZxroqkedLg/Pbirnd2/u40BNCykx4Sydk83SOTmMHg4LbSilzqCBrnrl8Rje3FPNn98r5bVdVQhw5aR07piXy0XjkrU7RqlhREe5qF45HMJlE9K4bEIah+ta+cu6Qzy5/jAvbz9KQVoMn744j5tmZBIRqsuHKTWcaQtd9ajD5eb5LRWseOcA2480khQdxu1zc7hj3hjS4nRMu1L+ol0u6rwZY3j/QB1/ePsA/yo5SohDuGHqaO64cAzTsxO0O0apIaZdLuq8iQjz8pOZl5/MwZoWHn33IH8tPszfN5UzJTOeO+aN4YZpo4kM0+4YpfxNW+jqnDV3uHhmYxmPrS1l99Fm4iNDuWVWFrfNzSE/Ncbf5SkV1LTLRQ2K490xj60t5eVtlbg8hlljEvnwrCyumzqKuIhQf5eoVNDRQFeDrqqpnWc2lvPXDWXsrWomPMTBoskZ3Dwzi3n5yTphSSkf0UBXQ8YYw9ayY/x1w2FWbT5CY7uL6DAnF45NZn5BKvMLUshLidaTqUqdJw105RftXW7e3F3Nmj3VrNlTQ2ltKwCZCZFcVpjKjdMzmTUmUcNdqXMw4EAXkUXA/YATeNgY839n2e5m4GlgtjGm17TWQB95SmtbWLOnhjV7qnlrdw1tXW6ykyK5cXomS6ZnMi5NT6gq1ZcBBbqIOIHdwJVAGbAeWGqM2XHadrHAC0AYcLcGuupNc4eLV7ZX8symct7ZW4PHwNSseBZNzmBhYRoT0mO15a5UDwYa6BcC9xhjrvbe/xaAMeZHp233S2A18DXgqxroqr+ONrbz3JYjPLu5nG3ljYDtllkwIZWFhWl8aGyKjnNXymugE4sygcPd7pcBc0/bwUwg2xjzgoh8rZdClgHLAHJycvqxazUSpMdFcNf8fO6an0/lsXZe31XFazureGZTOY+/f4jwEAfzC1K4clI6l09MJyUm3N8lKzUsDXimqIg4gJ8Dn+xrW2PMcmA52Bb6QPetgk9GfARL5+SwdE4OHS436w7U8WpJFat3HOVfJVWIfMCsnESuuiCdS8anMi41hhCnDolUCnzQ5SIi8cA+oNn7JxlAHbC4t24X7XJR58IYw46KRlbvOMrqHUfZfsR2zUSEOpg0Ko4pmfFMzoxnSlY8BWmxOB3a/66C00D70EOwJ0UvB8qxJ0VvM8ZsP8v2b6B96GqQldW3Unywng/Kj/FB2TG2HzlGS6cbgISoUC4am8LFBSlcPC6F7KQoP1erlO8MqA/dGOMSkbuBl7HDFlcYY7aLyL1AsTFmlW/LVapvWYlRZCVGceOMTMAu0rG/poWtZQ28s7eWt/dW88IHFQDkJkdxyfhUrp0yijm5STi09a6ClE4sUkHJGMO+6mbW7Knh7T01vLuvlrYuN+lx4Vw/dTQ3TBvNtKx4HRqpAo7OFFUjXiseCQ4AAAt5SURBVGuni1dLqli15Qhv7qqm0+0hOymSqydlcHFBCnPzknVopAoIGuhKdXOsrYtXtlfy3NYK1u6rpdPtIczpYOaYBOYXpHLxuBQKR8USHqIBr4YfDXSlzqKt0826g3W8s7eGNXtqKKmwo2dCHEJeSjTjM2IpTI9lQkYsU7MSyIjX5feUf+mKRUqdRWSYk0vHp3Lp+FQAqps6eP9ALSUVjeyqbGZrWQMvbLUnV0XgionpfOqiXC7MT9b+dzXsaAtdqT60dLjYfbSJV0uq+Mu6Q9S1dFKYEcunL8pj8fTRRIRq14waOtrlopSPtHe5+cfmch555yA7K5tIig5jZk4CkWEhRIY6iAoLITLMSXSYk/S4CDITI8lMiCQjPkL75JVPaJeLUj4SEerkI7NzuLUom/f21/LYe6UcrG2lvctNa6eLtk43bV1uutxnNpRSY8PJS4lm1phEZucmMisnifgoXaZP+Y620JUaBO1dbo42tlPe0EZ5fRtHGto50tDGzqNNbC8/hstj/90VpMVQlJvEzJwEZuQkkp8SrROfVK+0ha7UEIsIdTImOZoxydFnPNfW6Wbz4QY2lNZRXFrP81uPsHLdIQDiIkKYnpPI9OwEZmQnMHFUHOlx4XoCVvWLBrpSQyzSu8bqhWOTAXvZgn3VzWw61MCmww1sOlTPb17bg7cRT3xkKBMyYpmYEcuEjDgmZ8YxaVScXmVSnUEDXSk/cziEgvRYCtJjuXV2NmBH1mwrP8auo02UVDSxq7KRpzeUnbgAWXSYk5ljEpmdm8Ts3CSmZyfoTFelga7UcBQdHsLc/GTm5iefeMzjMZQ3tLH5cAPrD9ax7kAdv/jXboyxE6Gyk6LISowkyzuyxl7AzN6mxYZr3/wIoIGuVIBweEM7OymKG6aNBuBYaxcbDtWxobSeg7WtlNW3sXrHUWqaO0/521CnMDrBhn1WQhTJMWFEh4cQFeYkOjyE6LAQYiJCmJYVT0JUmD8OT/mABrpSASw+KpSFheksLEw/5fG2TjflDW0crm+lvL6Nsvo2yhvaKKtv5dWdVdS3duL2nDnCzSEwLTvhxOzZqVkJulhIANFhi0qNQMYYOt0eWjvctHS6aO10U9vcydr9tby5u5otZQ0YYxcLmTw6nvYuN80dLlo6XbR0uGnpcJGZEMnc/CTm5SczNy9Zr3MzRHSmqFLqnNS3dPL23hre3F3Nnqpmor1dMzHebpqoMCcHalp4/0AdTe0uAPJSopmbZ0/QTs1KYHy6rvc6GDTQlVKDwu0xlFQ0snZ/LWv317H+YB3H2roAu97rBaPjmZoVzwWj48lPjWZsSozOjh0gDXSl1JAwxlBa28qWsga2HD7G1rIGth05RnuX58Q2ydFh5KVEk58aTXpcBPGRocRHhpIQFUZ8ZCjJMWHkJkdr3/1Z6ExRpdSQEBFyU6LJTYlmyXS73qvL7aG0rpUD1S3sr2lmf3UL+2taeH1XNbXNHfRwbpaY8BA7WzYngZk5iczISdDRN/3Qr0AXkUXA/dhFoh82xvzfac9/GbgLcAHVwKeNMaU+rlUpFYBCnA7GpsYwNjUGOHU0jsdjaO50cay1i4bWLo61dVFxrI0tZQ1sLG3ggdf3ngj8tNhwkqLDSIoOIzE6jKSoMBKjQnE6HBjsRsaAAcJDHIxLi2FCeiw5SVEjZgx+n4EuIk7gAeBKoAxYLyKrjDE7um22CSgyxrSKyL8DPwE+MhgFK6WCh8MhxEWEEhcRSnbSycdvKTo5Y3Zr2TE2HqqntLaFupYuGlo7KalopL6lk4a2LvrqNY4MdVKQHsP49FjGpcWQmxxNbkoUY5Kig252bX9a6HOAvcaY/QAi8gSwBDgR6MaY17ttvxb4mC+LVEqNTNHhIadc9+Z0Ho9tmwt2RSmw3T4tHS72VDWzu7KJXUeb2FXZxBu7qnl6Q9kpf58eF86YpGiiw52EOh2EhTgIczoIdTqIiwyhIC2W8RmxFKTFEB0+/Huo+1NhJnC42/0yYG4v298JvDSQopRSqj/O1pUS7e2Dn56dcMrjje1dHKpt5WBtC6W1rRyoaeFwXSu1LZ10ujx0uj10uT10uQz1rZ10uE6ezM1KjGRCug34Cd51ZsemxhAWMnyGZvr0I0dEPgYUAZee5fllwDKAnJwcX+5aKaX6FBcRyuTMeCZnxve5rdtjKKtvZVdlE7uPNrH7aDO7Kpt4a0/1iQVMQhxih2OmxmAMtLvctHe5aevy0NHlJjzUyYT0GAoz4igcFUthRhxJ0YN3crfPYYsiciFwjzHmau/9bwEYY3502nZXAL8GLjXGVPW1Yx22qJQKRJ0uDwdqWthZ2Xgi7PfXtBDiECJCnUSEOAkPdRAZ6qS5w8XOyibqWk5eWyctNpzPzM/nM5fkn9f+BzpscT1QICJ5QDnwUeC203YwA3gQWNSfMFdKqUAVFuJgQobtcukPYwzVzR3sqmxiZ0UTOyubSIsLH5Ta+gx0Y4xLRO4GXsYOW1xhjNkuIvcCxcaYVcB9QAzwV+/KKoeMMYsHpWKllAogIkJabARpsRHML0gd1H31qw/dGPMi8OJpj/1Pt9+v8HFdSimlztHwOT2rlFJqQDTQlVIqSGigK6VUkNBAV0qpIKGBrpRSQUIDXSmlgoQGulJKBQm/rVgkItXA+V4zPQWo8WE5w1GwH2OwHx8E/zHq8fnHGGNMjzOU/BboAyEixWe7lkGwCPZjDPbjg+A/Rj2+4Ue7XJRSKkhooCulVJAI1EBf7u8ChkCwH2OwHx8E/zHq8Q0zAdmHrpRS6kyB2kJXSil1Gg10pZQKEgEX6CKySER2icheEfmmv+vxBRFZISJVIrKt22NJIrJaRPZ4bxP9WeNAiEi2iLwuIjtEZLuIfNH7eFAco4hEiMg6EdniPb7veR/PE5H3ve/VJ0Vk8BaTHAIi4hSRTSLyvPd+sB3fQRH5QEQ2i0ix97GAeo8GVKCLiBN4ALgGmAQsFZFJ/q3KJx4FFp322DeBV40xBcCr3vuBygV8xRgzCZgHfN77/y1YjrEDWGiMmQZMBxaJyDzgx8AvjDHjgHrgTj/W6AtfBEq63Q+24wO4zBgzvdv484B6jwZUoANzgL3GmP3GmE7gCWCJn2saMGPMW0DdaQ8vAf7o/f2PwI1DWpQPGWMqjDEbvb83YUMhkyA5RmM1e++Gen8MsBB42vt4wB4fgIhkAdcBD3vvC0F0fL0IqPdooAV6JnC42/0y72PBKN0YU+H9vRJI92cxviIiucAM4H2C6Bi93RGbgSpgNbAPaDDGuLybBPp79ZfA1wGP934ywXV8YD+EXxGRDSKyzPtYQL1H+7WmqPIvY4wRkYAfXyoiMcDfgP80xjR6FxQHAv8YjTFuYLqIJADPAIV+LslnROR6oMoYs0FEFvi7nkF0sTGmXETSgNUisrP7k4HwHg20Fno5kN3tfpb3sWB0VERGAXhvq/xcz4CISCg2zB83xvzd+3BQHSOAMaYBeB24EEgQkeONpkB+r14ELBaRg9huzoXA/QTP8QFgjCn33lZhP5TnEGDv0UAL9PVAgffsehjwUWCVn2saLKuAT3h//wTwDz/WMiDe/tY/ACXGmJ93eyoojlFEUr0tc0QkErgSe57gdeDD3s0C9viMMd8yxmQZY3Kx/+ZeM8bcTpAcH4CIRItI7PHfgauAbQTYezTgZoqKyLXY/jwnsMIY8wM/lzRgIrISWIC9XOdR4LvAs8BTQA72MsO3GmNOP3EaEETkYmAN8AEn+2C/je1HD/hjFJGp2BNmTmwj6SljzL0iko9t0SYBm4CPGWM6/FfpwHm7XL5qjLk+mI7PeyzPeO+GAH8xxvxARJIJoPdowAW6UkqpngVal4tSSqmz0EBXSqkgoYGulFJBQgNdKaWChAa6UkoFCQ10pZQKEhroSikVJP4/kkHWa2kCaM0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVa4eCdOEpuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "583402db-3210-4094-c111-b72669835d6c"
      },
      "source": [
        "model.load_state_dict(torch.load('model_cifar.pt'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pov1yXZaEwW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "bcd015aa-b986-43a9-e01c-684e88486f61"
      },
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update test loss \n",
        "        test_loss += loss.item()*data.size(0)\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)    \n",
        "        # compare predictions to true label\n",
        "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(batch_size):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.604421\n",
            "\n",
            "Test Accuracy of airplane: 85% (856/1000)\n",
            "Test Accuracy of automobile: 91% (915/1000)\n",
            "Test Accuracy of  bird: 69% (696/1000)\n",
            "Test Accuracy of   cat: 61% (613/1000)\n",
            "Test Accuracy of  deer: 79% (794/1000)\n",
            "Test Accuracy of   dog: 75% (756/1000)\n",
            "Test Accuracy of  frog: 87% (878/1000)\n",
            "Test Accuracy of horse: 85% (855/1000)\n",
            "Test Accuracy of  ship: 88% (889/1000)\n",
            "Test Accuracy of truck: 86% (868/1000)\n",
            "\n",
            "Test Accuracy (Overall): 81% (8120/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSUd6H8NEt-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}